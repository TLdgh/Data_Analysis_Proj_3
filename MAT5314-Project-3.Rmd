---
title: |
  | \vspace{-4em}MAT5314 Project 3: Queueing Theory
author: 
  - Teng Li(7373086)
  - Shiya Gao(300381032) 
  - Chuhan Yue(300376046)
  - Yang Lyu(8701121)
output: 
  pdf_document: 
    keep_tex: true
    includes:
      in_header: columns.tex
fontsize: 12pt
header-includes: 
  - \renewcommand{\and}{\\}
  - \usepackage{float}
  - \floatplacement{figure}{H}
bibliography: References.bib
link-citations: yes
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(plotly)
library(tidyverse)
library(kableExtra)
library(htmlwidgets)
library(webshot)
```

### Introduction

It is common that a passenger gets screened at an airfield for security and management purpose. This screening process involves some major steps such as scanning the boarding pass at entrance, serving the passenger, and exiting the service desk. This process can be described by queuing theory, in which a statistical model is built to analyze the waiting time and service processes. It allows to examine the relationship between inter-arrivals, service times and the capacity of the system demonstrated by calculating the number of servers needed to achieve certain quality of service level. In the end, one can gain an overall picture of the efficiency and dynamics of the screening process.

We were given four data sets containing the details of the screening process at the four major airfields of the nation. Our goal was to explain the data sets through data definitions and explanations, to explore the data sets by visualizing and analyzing their variables and possible relationships, and finally to perform the queuing analysis to predict the expected wait time at each airfield.

### Data Definition

```{r}
BASA<-read.csv("BASA_AUC_2028_912.csv", header = TRUE)
Flight<-read.csv("dat_F_sub.csv")
Passenger<-read.csv("dat_P_sub_c.csv")
Y2026<-read.csv("years20262030.csv")
```

The four data sets had common variables. The BASA data set was the biggest one containing most of the common variables, hence we used it as the main data set. We compared the variables between BASA and Passenger data and noticed that Passenger had unique variables with suffix "Flag", which we thought was not useful for our analysis. Other unique variables in Passenger were presented in other tables as well, hence these variables were omitted in our Queuing Analysis section. 
```{r}
setdiff(colnames(Passenger), colnames(BASA))
```

Similarly, the Flight data had variables that weren't really relevant or useful for our analysis, hence we also omitted them in Queuing Analysis.
```{r}
setdiff(colnames(Flight), colnames(BASA))
```

BASA and Y2026 had the same variables, except that Y2026 has airfields other than Auckland.

We gave a proper data definition in the following Table() for BASA data and for the unique variables in Passenger and Flight data in Table () and Table(). 

```{r}
DataDict<-BASA%>%select(-X)
DataDict<-data.frame(
  Variables=colnames(DataDict),
  Example=sapply(DataDict, function(x) paste(as.character(head(unique(x),1)), collapse = ", ")),
  Number.Unique=sapply(DataDict, function(x) length(unique(x))),
  PctMissing=sapply(DataDict, function(x) paste0(round(sum(is.na(x))/length(x), 4)*100,"%" ) ),
  Comment=c("Airfield from which the passenger departed: Auckland [AUC], Chebucto [CWL], Queenston [QUE], SaintFrancois [SAF]",
            "the date and time at which passengers exited the main queue S2, recorded to the nearest minute",
            "The waiting time of passenger in queue from S1 to S2, rounded up to the minute",
            "The number of security agents at S1 when passenger was scaned",
            "The number of security agents at S2 when passenger was scaned",
            "The average number of security agents at S1 and S2",
            "scheduled departure time",
            "actual departure time" ,
            "city of destination",
            "country of destination",
            "order",
            "ID for each passenger exited the main queue",
            "Departure_Date",
            "Departure_Time (recored in seconds: h*3600+m*60+s)",
            "departure time of day",
            "departure day is weekend or weeakday",
            "departure day in a week",
            "month of departure",
            "season of departure",
            "year of departure"
            ), row.names = NULL
)

DataDict%>%kable(booktabs = TRUE,caption = "BASA Variable Definition")%>%
  kable_styling(font_size=7, latex_options=c("striped","hold_position"))%>%
  column_spec(2, width = "8em")%>%
  column_spec(5, width = "15em")%>%
  row_spec(0,bold=TRUE)
```

```{r}
DataDict<-Passenger%>%select(setdiff(colnames(Passenger), colnames(BASA)))
DataDict<-data.frame(
  Variables=colnames(DataDict),
  Example=sapply(DataDict, function(x) paste(as.character(head(unique(x),2)), collapse = ", ")),
  Number.Unique=sapply(DataDict, function(x) length(unique(x))),
  PctMissing=sapply(DataDict, function(x) paste0(round(sum(is.na(x))/length(x), 4)*100,"%" ) ), 
  Comment=c("Valid passenger ID",
            "If Wait_Time is NA or not",
            "If S2 Schedule departure is NA or not",
            "If S2 Actural departure is NA or not",
            "If Schedule departure is NA or not",
            "Flight ID",
            "Delay in seconds"
            ),
  row.names = NULL
)

DataDict%>%kable(booktabs = TRUE,caption = "Passenger Variable Definition")%>%
  kable_styling(font_size=10, latex_options=c("striped","scale_down","hold_position"))%>%
  column_spec(2, width = "8em")%>%
  row_spec(0,bold=TRUE)
```

```{r}
DataDict<-Flight%>%select(setdiff(colnames(Flight), colnames(BASA)))
DataDict<-data.frame(
  Variables=colnames(DataDict),
  Example=sapply(DataDict, function(x) paste(as.character(head(unique(x),2)), collapse = ", ")),
  Number.Unique=sapply(DataDict, function(x) length(unique(x))),
  PctMissing=sapply(DataDict, function(x) paste0(round(sum(is.na(x))/length(x), 4)*100,"%" ) ),
  Comment=c("Flight ID",
            "total number of passengers",
            "actual number of passengers",
            "mimimum waiting time",
            "mean waiting time",
            "median waiting time",
            "maximum waiting time",
            "mean length of waiting time",
            "mean_City_Flag",
            "mode_BFO_Dest_City",
            "sum of the mode in the city",
            "number of destinated city",
            "mode_BFO_Dest_Country_Code",
            "sum of the mode in the country",
            "number of destinated country",
            "delay second"
            ), row.names = NULL
)

DataDict%>%kable(booktabs = TRUE,caption = "Flight Variable Definition")%>%
  kable_styling(font_size=10, latex_options=c("striped","scale_down","hold_position"))%>%
  column_spec(2, width = "8em")%>%
  row_spec(0,bold=TRUE)
```

We must also pointed out that there were flaws in these data sets that we had to correct. The BASA data contained the useful information from the Passenger data, as we have explained earlier. However there was a discrepancy of 10 minutes between the BASA Schedule Departure time and the Passenger Schedule Departure time. We believed that this difference is a minor mistake. BASA data contained the least amount of mistakes overall, hence another reason for us to use the BASA data directly in our Queuing analysis. In addition, The Period_of_Week variable did not match with the Day_of_Week, therefore we have cleaned all these flaws before doing the subsequent analyses.

```{r}
#clean BASA data:
BASA<-BASA%>%mutate(Period_of_Week=case_when(
    Day_of_Week=="6 - SAT" | Day_of_Week=="7 - SUN" ~ "2 - WEEKEND",
    .default = "1 - WEEKDAY"
), S2=as.POSIXct(S2))

#BASA[which(BASA$Time_of_Day=="1 - NIGHT"),"Time_of_Day"]<-"4 - EVENING"
```


### Data exploration

In the data Y2026, there were only two kinds of seasons: winter and autumn. Autumn contained only 7 data points and winter had 3219 points, which in total accounted for the bulk of the data. One can see from the Airfield column that although it contained the most types of airfields among the four data sets, except for SaintFrancois(SAF), the other three airfields had negligible proportions. The airfields in the data set BASA were all Auckland (AUC), whereas in Y2026 there were only four data points for which the airfield was AUC. Compared with BASA, Y2026 provided too little information. If we analyze the data of Y2026 based on the combination of categories of Time_of_ Day, Day_of_Week and Season respectively, the count of arrivals of Y2026 in most of clusters was almost zero, that is to say, the data of Y2026 was not very useful to the overall analysis, so we discard this data set.
```{r, results='asis'}
ftable(Y2026[, c("Airfield", "Season", "Time_of_Day", "Day_of_Week")])
```

### Queuing Analysis

```{r}
#make list of 16 clusters:
BASA_fill <- split(BASA, list(BASA$Season, BASA$Period_of_Week, BASA$Time_of_Day))

# fill missing wait time with mean
fill_missing <- function(df){
  mean_value <- round(mean(df$Wait_Time, na.rm = TRUE),0)
  df$Wait_Time[is.na(df$Wait_Time)] <- mean_value
  return(df)
}

BASA_fill<-map(BASA_fill, fill_missing)
```


```{r}
MakeTbl<-function(cluster){
  if(is_empty(unique(cluster$Period_of_Week))==TRUE){
    Result <- data.frame(Season=NaN, Period_of_Week=NaN,Time_of_Day=NaN,Count=NaN,Minute=NaN,Arrival_Rate=NaN,Avg_Wait_Time=NaN,Service_Rate=NaN,Avg_Servers=NaN)
  }else{
    if(unique(cluster$Period_of_Week)=="1 - WEEKDAY"){Minute<-13*5*6*60}else{Minute<-13*2*6*60}
    #Minute<-difftime(max(cluster$S2),min(cluster$S2), units = "mins")%>%as.numeric()
    
    Count<-nrow(cluster) #number of arrivals
    lambda <-Count/Minute #lambda is the arrival rate (number of arrivals per unit time)
    Wq <- mean(cluster$Wait_Time) #Wq is the average wait time
    mu <- (Wq*lambda+sqrt((Wq*lambda)^2+4*Wq*lambda))/(2*Wq) #mu is the service rate per unit time
    c <- mean(cluster$C0,na.rm = TRUE)
    
    Result <- data.frame(Season=unique(cluster$Season),Period_of_Week=unique(cluster$Period_of_Week),
                         Time_of_Day=unique(cluster$Time_of_Day),Count,Minute=Minute,Arrival_Rate=lambda,
                         Avg_Wait_Time=Wq,Service_Rate=mu,Avg_Servers=c)
  }
  return(Result)
}
Result<-do.call(rbind, map(BASA_fill, MakeTbl))
```

```{r}
Result%>%select(-c(Season, Period_of_Week,Time_of_Day))%>%
  kable(booktabs = TRUE,caption = "Result")%>%
  kable_styling(font_size=7, latex_options=c("striped","scale_down", "hold_position"))%>%
  row_spec(0,bold=TRUE)
```

Regression Model
$\mu=\mu(\lambda,c)=ac+b\lambda$
$\frac{\mu}{c}=b\frac{\lambda}{c}+a$

```{r}
regression_data <-Result%>%transmute(Avg_Servers, Arrival_Rate,Service_Rate,
                                    arrival_rate_perserver=Arrival_Rate/Avg_Servers,
                                    service_rate_perserver=Service_Rate/Avg_Servers)

# Regression model
regression_model<- lm(service_rate_perserver ~ arrival_rate_perserver,data = regression_data[-c(1,9,13),])
summary(regression_model)
```

```{r}
regression_data%>%
  kable(booktabs = TRUE,caption = "Regression Data")%>%
  kable_styling(font_size=7, latex_options=c("striped","scale_down", "hold_position"))%>%
  row_spec(0,bold=TRUE)
```

$service\_rate\_perserver=1.43244*arrival\_rate\_perserver+0.03544 $
$\frac{\mu}{c}=1.43244 \frac{\lambda}{c}+0.03544$
$\mu=1.43244\lambda+0.03544c$
implies that $\hat{a}=0.03544$ and $\hat{b}=1.43244$, where $\lambda$ is the arrival rate, $c$ is the average number of servers, $\mu$ is the service rate.

```{r}
plot(regression_data[-c(3,4),]$arrival_rate_perserver, regression_data[-c(3,4),]$service_rate_perserver, pch = 16, col = "blue", xlab = "Arrival rate per server", ylab = "Service rate per server", main = "Regression Line and Points")

abline(regression_model, col = "red")

legend("topleft", legend = c("Points", "Regression Line"), col = c("blue", "red"), pch = c(16, NA), lty = c(NA, 1))
```

In our data, we have $\lambda<\hat{\mu}$, QoS level $\mathbb{P}(x)=1-\frac{\lambda}{\hat{a}c+\hat{b}\lambda}e^{-(\hat{a}c+\hat{b}\lambda-\lambda)x}=1-\frac{\lambda}{0.03544c+1.43244\lambda}e^{-(0.03544c+1.43244\lambda-\lambda)x}$

```{r}
# prediction of prob of waittime <x for given cluster related information and time x
predict_prob_waittime <- function(season, PeriodOfWeek, PeriodOfDay,x){
  match_set <- Result %>% filter(Season == season,Period_of_Week == PeriodOfWeek,Time_of_Day == PeriodOfDay)
  my_lambda <-match_set$Arrival_Rate
  my_mu <-match_set$Service_Rate
  my_c <-match_set$Avg_Servers
  a_hat<-0.03544
  b_hat<-1.43244
  Pr<-1-my_lambda/(a_hat*my_c+b_hat*my_lambda)*exp(-(a_hat*my_c+b_hat*my_lambda-my_lambda)*x)
  return(round(Pr,5))
}

PlotCDF<-function(df, Time){
  df<-cbind(Time, df)%>%gather("Cluster", "Value",2:(length(df)-1))
  p<-ggplot(df, aes(x = Time, y = Value, color = Cluster)) +
      geom_line() +
      labs(title = paste("CDF of Cluster"), x = "Time in mins", y = "CDF")
  print(p)
  }
```

```{r}
checkpoint <-seq(5,30,5)

P<-apply(Result, 1, function(x){
  res<-sapply(checkpoint, function(val){predict_prob_waittime(season=x[1],PeriodOfWeek=x[2],PeriodOfDay=x[3],x=val)})
  return(res)
})%>%t()
dimnames(P)<-list(rownames(Result), paste0("Pr(<", checkpoint, " mins)") )
P%>%kable(booktabs = TRUE,caption = "Performance Level")%>%
  kable_styling(font_size=7, latex_options=c("striped","scale_down","hold_position"))%>%
  row_spec(0,bold=TRUE)%>%
  column_spec(1,bold=TRUE)
```

```{r}
checkpoint <-0.0000001*exp(seq(0.1,19.5,0.1))

P<-apply(Result, 1, function(x){
  res<-sapply(checkpoint, function(val){predict_prob_waittime(season=x[1],PeriodOfWeek=x[2],PeriodOfDay=x[3],x=val)})
  return(res)
})
dimnames(P)<-list(paste0("Pr(<", checkpoint, " mins)"), rownames(Result) )
P<-as.data.frame(P)

PlotCDF(P, Time = checkpoint)
```

### References



